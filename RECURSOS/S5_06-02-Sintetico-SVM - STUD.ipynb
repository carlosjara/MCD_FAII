{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVMs (Support Vector Machines) con datos sintéticos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basado en el capítulo 9 del libro \"Introduction to Statistical Learning\" de Gareth James, Daniela Witten, Trevor Hastie y Robert Tibshirani."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos las librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#warnings.filterwarnings(action=‘ignore’,category=DeprecationWarning)\n",
    "#warnings.filterwarnings(action=‘ignore’,category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Creación de un dataset sintético aleatorio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicialmente, vamos a generar aleatoriamente un dataset sencillo de ensayo (20 instancias) para comprender como funciona el algoritmo SVM con un kernel lineal. El dataset va a tener dos variables numéricas predictoras (x1 y x2) y una clase (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(5)\n",
    "X = np.random.randn(20,2)\n",
    "y = np.repeat([1,-1], 10)\n",
    "\n",
    "# Trasladamos los puntos de la clase negativa un poco a la derecha, para incentivar la separabilidad lineal\n",
    "X[y == -1] = X[y == -1] +1  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos un dataframe con los datos anteriores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0 = pd.concat([    pd.DataFrame(X), pd.DataFrame(y)   ], axis = 1)\n",
    "df_0.columns = ['x1', 'x2', 'y']\n",
    "df_0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(index=df_0[\"y\"], columns=\"count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a ilustrar un particionamiento posible con los dataframes, usando el método **groupby**.\n",
    "La idea es poder obtener subconjuntos de datos dados diferentes valores de una misma variable categórica.\n",
    "En este caso, tenemos la varible objetivo *y*, que nos servirá como criterio de particionamiento.\n",
    "\n",
    "El método *groupby* retorna una tupla con la categoría de la variable particionada (-1 o +1), y un dataframe con los registros correspondientes a cada categoría, incluyendo el índice (de la fila original) de los registros correspondientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, group in df_0.groupby('y'):\n",
    "    print(\"Grupo para la clase {}\\n{}\".format(name, group))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos entonces a visualizar los datos en un scatterplot para poder entenderlos mejor. Vamos a utilizar un scatterplot y un gráfico de densidad de 2 dimensiones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize=[15, 5], ncols=2, nrows=1)\n",
    "\n",
    "for name, group in df_0.groupby('y'):\n",
    "    sns.scatterplot(x=\"x1\", y=\"x2\", data=group, alpha=0.5, label=name, ax=axs[0])    \n",
    "axs[0].legend()\n",
    "axs[0].set_title(\"ScatterPlot: x1 vs. x2\")\n",
    "\n",
    "for name, group in df_0.groupby('y'):\n",
    "    sns.kdeplot(data=group[\"x1\"], data2=group[\"x2\"], shade=True, shade_lowest=False, alpha=0.5,\n",
    "                label=name, ax=axs[1])    \n",
    "axs[1].legend(loc=2)\n",
    "axs[1].set_title(\"Densidad de puntos: x1 vs. x2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Entrenamiento de un modelo SVM de Clasificación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En Python, los modelos SVM de clasificación son representados por la clase **SVC**. En el caso de clasificación con más de 2 clases, **SVC** adopta una aproximación \"uno contra uno\" para determinar la clase final.\n",
    "\n",
    "Esta clase se crea con los siguientes parámetros:\n",
    "\n",
    "- *C*: valor de la penalidad de una instancia por violación de las márgenes (1 por defecto); controla la regularización. A menor valor de C, mayor amplitud de la margen del clasificador\n",
    "- *kernel*: el tipo de kernel a utilizar ('rbf' por defecto); otros valores aceptados son: ‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’. Se puede definir un kernel implementado en una clase por fuera del API. \n",
    "- *degree*: grado del polinomio en el caso del kernel 'poly' (3 por defecto); se ignora para otros kernels.\n",
    "- *gamma*: determina la dispersión alrededor de los vectores de soporte ('auto' por defecto); solo se considera para los kernels ‘rbf’, ‘poly’ y ‘sigmoid’. A mayor *gamma*, mayor complejidad (dimensionalidad) del espacio de representación de las instancias.\n",
    "- *probability* : Indica si se deben generar estimados de probabilidad de clase (False por defecto), lo que implicaría un costo en el tiempo de procesamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intentamos la clasificación con un kernel **lineal**, usando entonces un **clasificador de margen suave**. Como los datos no son linealmente separables, es necesario establecer un valor de C > 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(C=1, kernel='linear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A manera de ilustración, vamos a entrenarlo con todo el dataset (uds ya saben que esto no se debe hacer!!! Pero vamos a ir aumentando la complejidad del proceso poco a poco)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el modelo entrenado podemos tener acceso a los vectores de soporte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"De los {} puntos de entrenamiento, {} son vectores de soporte\".format(len(y), len(svc.support_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a definir una función **plot_svc** (tomado de R. Jordan Crouser @ Smith College) que nos permitirá visualizar los resultados de la aplicación de un modelo de SVM para la clasificación de un conjunto de datos. Recibe:\n",
    "\n",
    "- svc: El modelo entrenado de tipo SVC\n",
    "- X: La matriz con las variables predictoras X, del dataset a evaluar\n",
    "- y: El array con las clases verdaderas correspondientes, del dataset a evaluar\n",
    "- pad: El tamaño del borde a dejar sin puntos, valor por defecto 0.25\n",
    "- h: la distancia entre los puntos en la grilla a evaluar, valor por defecto 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_svc(svc, X, y, h=0.02, pad=0.25):\n",
    "    # Determinamos los límites del plot a gráficar\n",
    "    x1_min, x1_max = X[:, 0].min()-pad, X[:, 0].max()+pad\n",
    "    x2_min, x2_max = X[:, 1].min()-pad, X[:, 1].max()+pad\n",
    "\n",
    "    # Creamos una grilla de puntos que se van a enviar al clasificador (meshgrid)\n",
    "    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, h), np.arange(x2_min, x2_max, h))\n",
    "    \n",
    "    # Usando unravel(), vamos aplanar las matrices xx1 y xx2, creando una gran lista de puntos que se enviarán al modelo\n",
    "    Z = svc.predict(np.c_[xx1.ravel(), xx2.ravel()]) #En Z quedan las clases predichas para cada punto de la grilla\n",
    "\n",
    "    # Ploteamos la grilla con sus clases\n",
    "    Z = Z.reshape(xx1.shape)\n",
    "    plt.contourf(xx1, xx2, Z, cmap=plt.cm.Paired, alpha=0.2)\n",
    "\n",
    "    # Ploteamos los puntos evaluados con sus clases reales\n",
    "    plt.scatter(X[:, 0], X[:, 1], s=70, c=y, cmap=plt.cm.Paired)\n",
    "\n",
    "    # Identificamos los vectores de soporte del modelo con una x\n",
    "    sv = svc.support_vectors_\n",
    "    plt.scatter(sv[:,0], sv[:,1], c='k', marker='x', s=100, linewidths=1)\n",
    "\n",
    "    plt.xlim(x1_min, x1_max)\n",
    "    plt.ylim(x2_min, x2_max)\n",
    "    plt.xlabel('x1')\n",
    "    plt.ylabel('x2')\n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos como nos va con todo el dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_svc(svc, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos el espacio de representación bidimensional de los datos dividido en 2 por una frontera de decisión dada por el clasificador. Dado el kernel utilizado por el modelo, la frontera es lineal.\n",
    "\n",
    "Encontramos unos cuantos errores, y podemos ver los puntos que intervienen como **vectores de soporte**, graficados con una \"x\". Podemos ver que estos puntos están cerca de la frontera de decisión. Algunos de ellos están en el lado de decisión incorrecto, no solo violan la margen, sino que quedan mal clasificados. Otros puntos están en el buen lado, pero violan la margen establecida por el clasificador (la margen no es visible).\n",
    "\n",
    "Podemos identificar los vectores de soporte con las variables **support_**, que indica los índices de los puntos, y **support_vectors_**, que contiene su representación en el espacio de las variables independientes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc.support_vectors_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El parámetro *C* del modelo controla el valor de cada violación de la margen. \n",
    "Se trata de un parámetro de regularización que permite encontrar un balance entre las contribuciones del error de sesgo y de varianza.\n",
    "\n",
    "Entre más pequeño sea de *C*, mayor será el margen y mas puntos quedarán identificados como vectores de soporte (tendiendo hacia el **underfitting**). \n",
    "Al contrario, entre más grande sea *C*, menor el margen y menor la cantidad de vectores de soporte (tendiendo hacia el **overfitting**). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación vamos a crear otro modelo SVM con otro valor de C, para entender mejor su influencia en los resultados obtenidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(C=0.01, kernel='linear')\n",
    "svc.fit(X, y)\n",
    "print(\"De los {} puntos de entrenamiento, {} son vectores de soporte\".format(len(y), len(svc.support_)))\n",
    "plot_svc(svc, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(C=0.1, kernel='linear')\n",
    "svc.fit(X, y)\n",
    "print(\"De los {} puntos de entrenamiento, {} son vectores de soporte\".format(len(y), len(svc.support_)))\n",
    "plot_svc(svc, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos ahora a utilizar la clase **GridSearchCV** para aplicar el protocolo de evaluación de cross-validation y así poder estimar la mejor combinación de valores de los parámetros configurables de un modelo. Variaremos *C*, utilizando *accuracy* como métrica de evaluación.\n",
    "\n",
    "En total se evaluarán 7 valores de cada uno de los dos parámetros, por lo que ensayaremos se crearán 7 modelos con configuraciones diferentes, cada uno con varias repeticiones de cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "parametros = [{'C': [0.001, 0.01, 0.1, 1, 5, 10, 100]}]\n",
    "clf = GridSearchCV(SVC(kernel='linear'), # el modelo a configurar\n",
    "                   parametros, # los parámetros con los valores a ensayar\n",
    "                   cv=10, # para cada modelo se hacen 10 repeticiones\n",
    "                   scoring='accuracy', # métrica de evaluación a considerar para decidir el mejor modelo\n",
    "                   return_train_score=True) # guardar en memoria los valores de las métricas de evaluación\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La búsqueda por grilla graba la configuración y los resultados de la evaluación del mejor modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_index_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos acceder a los resultados de las evaluaciones, utilizando el diccionario que queda en la variable cv_results_.\n",
    "Se puede consultar en su totalidad:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.cv_results_.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También se puede consultar elemento por elemento, dado que es un diccionario:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.cv_results_['mean_train_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Predicción con el modelo entrenado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos un SVC con kernel lineal y la mejor configuración encontrada (C=0.001) y lo usamos para predecir las clases, utilizando el método **predict** sobre un nuevo dataset de test que siga el mismo proceso generador del dataset de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "X_test = np.random.randn(20,2)\n",
    "y_test = np.random.choice([-1,1], 20)\n",
    "X_test[y_test == 1] = X_test[y_test == 1] -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc2 = SVC(C=0.1, kernel='linear', probability=True)\n",
    "svc2.fit(X, y)\n",
    "y_pred = svc2.predict(X_test)\n",
    "pd.DataFrame(confusion_matrix(y_test, y_pred), index=svc2.classes_, columns=svc2.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos 14 instancias bien clasificadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos obtener el valor de decisión que permite eventualmente ver que tan lejos se está o no de las márgenes, y en que lado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc2.decision_function(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí podemos ver que solo hay dos puntos clasificados en la clase negativa, y la magnitud de este valor nos indica el nivel de confianza del clasificador, tal como lo indican las probabilidades de clase que se obtienen con la función **predict_proba** (solo disponible si se ha creado el objeto **SVC** con probability=True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc2.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. SVMs con un dataset linealmente separable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modificamos el dataset de test anterior para que sea apenas linealmente separable (muy justo), y analizamos los resultados de varias configuraciones de un SVM aprendido sobre él"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[y_test == 1] = X_test[y_test == 1] -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_test[:,0], X_test[:,1], s=70, c=y_test, cmap=plt.cm.Paired)\n",
    "plt.xlabel('X1')\n",
    "plt.ylabel('X2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenemos un modelo (utilizando el test set como set de aprendizaje, solo como ilustración) que garantice que todas las instancias están bien clasificadas, acercándose a lo que sería un **clasificador de margen dura**. Para tal motivo, vamos a especificar un gran valor del parámetro *C* (10000), para que cada error tenga un gran valor y se busque la perfección de la clasificación del set de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc3 = SVC(C=1e5, kernel='linear')\n",
    "svc3.fit(X_test, y_test)\n",
    "plot_svc(svc3, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que en efecto que no hubo errores en el entrenamiento, y que solo tenemos 3 vectores de soporte.\n",
    "Como hay muchos puntos cercanos a la frontera de decisión que no son vectores de soporte, podemos asimilar que la margen es bastante angosta.\n",
    "Podríamos estimar que este modelo es demasiado rigido y no tiene una buena capacidad de generalización (overfitting)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intentemos con un valor de C=1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc4 = SVC(C=1, kernel='linear')\n",
    "svc4.fit(X_test, y_test)\n",
    "plot_svc(svc4, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aunque hay un error, vemos que hay una mayor cantidad de vectores de soporte alejados de la frontera de decisión, por lo que este modelo puede ser mas robusto frente al overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Creación de un dataset sintético no linealmente separable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, vamos a generar aleatoriamente un dataset sencillo de ensayo (300 instancias) para comprender como funciona el algoritmo, que va a tener dos variables numéricas predictoras (x1 y x2) y una clase (y):\n",
    "\n",
    "- Las primeras 100 instancias van a tener valores pequeños en las dos variables, y se asignarán a la clase -1\n",
    "- Las 100 instancias intermedias van a tener valores medianos en las dos variables, y se asignarán a la clase +1\n",
    "- Las últimas 100 instancias van a tener valores grandes en las dos variables, y se asignarán a la clase -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(12345)\n",
    "X = np.random.randn(300,2)\n",
    "X[:100] = X[:100] -2.5\n",
    "X[201:] = X[201:] +2.5\n",
    "y = np.concatenate([np.repeat(-1, 100), np.repeat(1,100), np.repeat(-1, 100)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos un dataframe con los datos anteriores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0 = pd.concat([    pd.DataFrame(X), pd.DataFrame(y)   ], axis = 1)\n",
    "df_0.columns = ['x1', 'x2', 'y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agrupamos por clases y visualizamos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize=[15, 5], ncols=2, nrows=1)\n",
    "\n",
    "for name, group in df_0.groupby('y'):\n",
    "    sns.scatterplot(x=\"x1\", y=\"x2\", data=group, alpha=0.5, label=name, ax=axs[0])    \n",
    "axs[0].legend()\n",
    "axs[0].set_title(\"ScatterPlot: x1 vs. x2\")\n",
    "\n",
    "for name, group in df_0.groupby('y'):\n",
    "    sns.kdeplot(data=group[\"x1\"], data2=group[\"x2\"], shade=True, shade_lowest=False, alpha=0.5,\n",
    "                label=name, ax=axs[1])    \n",
    "axs[1].legend(loc=2)\n",
    "axs[1].set_title(\"Densidad de puntos: x1 vs. x2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento y búsqueda de parámetros para un modelo SVM de Clasificación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a generar un conjunto de datos de entrenamiento y un set de evaluación utilizando la función **train_test_split**, dejando el 70% de los datos en el primer conjunto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=666)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a crear un clasificador SVM con la clase **SVC**, a entrenarlo y a visualizar su frontera de clasificación y su error de test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc3 = SVC(C=10, kernel='rbf', gamma=1)\n",
    "svc3.fit(X_train, y_train)\n",
    "print(\"De los {} puntos de entrenamiento, {} son vectores de soporte\".format(len(y_train), len(svc3.support_)))\n",
    "plot_svc(svc3, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_svc(svc3, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svc3.predict(X_train)\n",
    "pd.DataFrame(confusion_matrix(y_train, y_pred), index=svc3.classes_, columns=svc3.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svc3.predict(X_test)\n",
    "pd.DataFrame(confusion_matrix(y_test, y_pred), index=svc3.classes_, columns=svc3.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con C=10, encontramos 7 errores de entrenamiento y 9 errores de test de 90 (90% de accuracy)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos que pasa si incrementamos el valor de la sensibilidad a los errores a 100, haciendo que la margen sea más angosta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increasing C parameter, allowing more flexibility\n",
    "svc4 = SVC(C=100, kernel='rbf', gamma=1.0)\n",
    "svc4.fit(X_train, y_train)\n",
    "print(\"De los {} puntos de entrenamiento, {} son vectores de soporte\".format(len(y_train), len(svc4.support_)))\n",
    "plot_svc(svc4, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que empieza a presentar overfitting, con una frontera de decisión más compleja que incluye \"islas\" para evitar errores. \n",
    "En cuanto a la calidad de las predicciones tenemos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svc4.predict(X_train)\n",
    "pd.DataFrame(confusion_matrix(y_train, y_pred), index=svc4.classes_, columns=svc4.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svc4.predict(X_test)\n",
    "pd.DataFrame(confusion_matrix(y_test, y_pred), index=svc3.classes_, columns=svc3.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con C=100, encontramos 2 errores de entrenamiento y 53 errores de test de 90 (41.1% de accuracy)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, hagamos variar el parámetro **gamma**, del kernel **rbf**, que controla la amplitud de la gaussiana. Teniendo en cuenta que el valor original era 1, analicemos el efecto de utilizar valores más pequeños (0.1) y más grandes (5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc5 = SVC(C=10, kernel='rbf', gamma=0.1)\n",
    "svc5.fit(X_train, y_train)\n",
    "print(\"De los {} puntos de entrenamiento, {} son vectores de soporte\".format(len(y_train), len(svc5.support_)))\n",
    "plot_svc(svc5, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encontramos que a menor **gamma**, mas sencillo el modelo,  menor número de vectores de soporte y se tiende hacia el underfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc6 = SVC(C=10, kernel='rbf', gamma=5)\n",
    "svc6.fit(X_train, y_train)\n",
    "print(\"De los {} puntos de entrenamiento, {} son vectores de soporte\".format(len(y_train), len(svc6.support_)))\n",
    "plot_svc(svc6, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encontramos que entre mayor el **gamma**, mas complejo el modelo por lo que más vectores de soporte, y mas overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilicemos ahora **GridSearchCV** para estimar la mejor combinación de valores de los parámetros configurables (en este caso variaremos *C* y *gamma*), con respecto a una métrica de evaluación (en este caso utilizaremos el *accuracy*).\n",
    "En total se evaluarán 5 valores de cada uno de los dos parámetros, por lo que ensayaremos con 25 configuraciones diferentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = [{'C': [0.01, 0.1, 1, 10, 100],\n",
    "                     'gamma': [0.5, 1,2,3,4]}]\n",
    "clf = GridSearchCV(SVC(kernel='rbf'), tuned_parameters, cv=10, scoring='accuracy', return_train_score=True)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encontramos que la mejor configuración fue C=1 con gamma=1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analicemos la matriz de confusión:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, clf.best_estimator_.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos un 91.1% de accuracy sobre la clasificación con el mejor modelo encontrado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_estimator_.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos como serían las curvas de la métrica ROC AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(kernel=\"rbf\", C=1, gamma=1)\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = svc.predict(X_train)\n",
    "accuracy_score(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = svc.predict(X_test)\n",
    "accuracy_score(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_pos_rate, true_pos_rate, _ = roc_curve(y_train, y_train_pred)\n",
    "roc_auc = auc(false_pos_rate, true_pos_rate)\n",
    "false_pos_rate_test, true_pos_rate_test, _ = roc_curve(y_test, y_test_pred)\n",
    "roc_auc_test = auc(false_pos_rate_test, true_pos_rate_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1) = plt.subplots(1, 1, figsize=(6,6))\n",
    "\n",
    "ax1.plot(false_pos_rate, true_pos_rate, label='Training' % roc_auc, color='b')\n",
    "ax1.plot(false_pos_rate_test, true_pos_rate_test, label='Test' % roc_auc_test, color='g')\n",
    "ax1.set_title('Comparación del ROC del SVM')\n",
    "\n",
    "for ax in fig.axes:\n",
    "    ax.plot([0, 1], [0, 1], 'k--')\n",
    "    ax.set_xlim([-0.05, 1.0])\n",
    "    ax.set_ylim([0.0, 1.05])\n",
    "    ax.set_xlabel('False Positive Rate')\n",
    "    ax.set_ylabel('True Positive Rate')\n",
    "    ax.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
