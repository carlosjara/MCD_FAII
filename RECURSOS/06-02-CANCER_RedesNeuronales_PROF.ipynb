{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gyn12JhN2uy1",
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Redes-neuronales\" data-toc-modified-id=\"Redes-neuronales-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Redes neuronales</a></span><ul class=\"toc-item\"><li><span><a href=\"#Entendimiento-de-los-datos\" data-toc-modified-id=\"Entendimiento-de-los-datos-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Entendimiento de los datos</a></span></li><li><span><a href=\"#Pretratamiento\" data-toc-modified-id=\"Pretratamiento-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Pretratamiento</a></span></li><li><span><a href=\"#Modelamiento\" data-toc-modified-id=\"Modelamiento-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Modelamiento</a></span><ul class=\"toc-item\"><li><span><a href=\"#activation\" data-toc-modified-id=\"activation-1.3.1\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span>activation</a></span></li><li><span><a href=\"#max_iter\" data-toc-modified-id=\"max_iter-1.3.2\"><span class=\"toc-item-num\">1.3.2&nbsp;&nbsp;</span>max_iter</a></span></li><li><span><a href=\"#hidden_layer_sizes\" data-toc-modified-id=\"hidden_layer_sizes-1.3.3\"><span class=\"toc-item-num\">1.3.3&nbsp;&nbsp;</span>hidden_layer_sizes</a></span></li><li><span><a href=\"#learning_rate_init\" data-toc-modified-id=\"learning_rate_init-1.3.4\"><span class=\"toc-item-num\">1.3.4&nbsp;&nbsp;</span>learning_rate_init</a></span></li><li><span><a href=\"#mejor-combinación\" data-toc-modified-id=\"mejor-combinación-1.3.5\"><span class=\"toc-item-num\">1.3.5&nbsp;&nbsp;</span>mejor combinación</a></span></li><li><span><a href=\"#DESDE-AQUÍ:-NO-EJECUTAR-DE-NUEVO-(+20-minutos)\" data-toc-modified-id=\"DESDE-AQUÍ:-NO-EJECUTAR-DE-NUEVO-(+20-minutos)-1.3.6\"><span class=\"toc-item-num\">1.3.6&nbsp;&nbsp;</span><font color=\"red\"><b>DESDE AQUÍ: NO EJECUTAR DE NUEVO (+20 minutos)</b></font></a></span></li><li><span><a href=\"#HASTA-ACÁ-(+20-minutos)\" data-toc-modified-id=\"HASTA-ACÁ-(+20-minutos)-1.3.7\"><span class=\"toc-item-num\">1.3.7&nbsp;&nbsp;</span><font color=\"red\"><b>HASTA ACÁ (+20 minutos)</b></font></a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QuEN45Kh2uzS"
   },
   "source": [
    "# Redes neuronales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4B5VqQy-2uzT"
   },
   "source": [
    "Vamos a crear un modelo de clasificación de cancer de seno con una sencilla red neuronal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iKmXrjuI2uzU"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd #tratamiento de datos\n",
    "import matplotlib.pyplot as plt #gráficos\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split #metodo de particionamiento de datasets para evaluación\n",
    "from sklearn.model_selection import cross_val_score, cross_validate #método para evaluar varios particionamientos de C-V\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, RepeatedKFold, LeaveOneOut #Iteradores de C-V\n",
    "from sklearn.model_selection import GridSearchCV #permite buscar la mejor configuración de parámetros con C-V\n",
    "from sklearn.metrics import accuracy_score, cohen_kappa_score, classification_report\n",
    "from sklearn.metrics import make_scorer # permite crear una clase scorer a partir de una función de score (necesario para el kappa)\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IFTeJvK42uzX"
   },
   "source": [
    "## Entendimiento de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MkmGszwL2uzX"
   },
   "outputs": [],
   "source": [
    "cancer = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HlIvJvx82uzY",
    "outputId": "f718b6e8-8bcf-474a-e99b-86a9a548d131"
   },
   "outputs": [],
   "source": [
    "print(cancer['DESCR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "93uTCUE22uza"
   },
   "source": [
    "Tenemos un baseline que clasifica en maligno, con 357 instancias benignas vs 212 malignas (62.7%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "21_rstrU2uzb",
    "outputId": "9a47a0d2-65fc-4d58-8322-c0e1645977b6"
   },
   "outputs": [],
   "source": [
    "cancer.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TaaaABP-2uzc",
    "outputId": "571b00d3-d4b5-400c-d538-aefeffd80b2e"
   },
   "outputs": [],
   "source": [
    "cancer.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K0X8d7Eb2uzd"
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame(cancer.data)\n",
    "data.columns = cancer.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 990
    },
    "id": "3mPp2-F72uze",
    "outputId": "5454400e-82d7-4a8b-aaf8-a69af3cf7be9"
   },
   "outputs": [],
   "source": [
    "data.describe(include=\"all\").T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "apWvIZoR2uze"
   },
   "source": [
    "Vemos que no hay missing values, y que todas las variables independientes con numéricas.\n",
    "Creamos los datasets de training y de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XVDK_rwu2uzf"
   },
   "outputs": [],
   "source": [
    "X = cancer['data']\n",
    "y = cancer['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_lmaHze02uzg"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rCFkLXJaj291"
   },
   "outputs": [],
   "source": [
    "df_X_train = pd.DataFrame(X_train, columns=cancer.feature_names)\n",
    "df_y_train = pd.DataFrame(y_train, columns=['target'])\n",
    "df_X_test = pd.DataFrame(X_test, columns=cancer.feature_names)\n",
    "df_y_test = pd.DataFrame(y_test, columns=['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KhT-TToFk9zb",
    "outputId": "0df5cd10-cd09-48c3-8c08-f502fcdccbcf"
   },
   "outputs": [],
   "source": [
    "print(f\"Train: {df_X_train.shape}, {df_y_train.shape}\")\n",
    "print(f\"Test: {df_X_test.shape}, {df_y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X64CnMyP2uzi"
   },
   "source": [
    "## Pretratamiento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eOfAaOD52uzi"
   },
   "source": [
    "Normalizar **no es necesario ni para las redes neuronales** desde el punto de vista que, como con la **regresión logística**, no cambia las capacidades predictivas del modelo, solo la magnitud de los coeficientes y su posible interpretación (en regresión logística, ya que en redes neuronales no es posible pensar en términos de inferencia).\n",
    "\n",
    "Sin embargo, normalizar es una buena práctica en el sentido de que puede mejorar el número de épocas de entrenamiento necesarias, y se puede llegar a convertir en una práctica obligatoria en el caso de redes muy profundas, sobre las cuales el **gradiente** del error propagado puede **saturarse** o **desvanecerse**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EYXbyU9M2uzj"
   },
   "source": [
    "Creamos entonces un objeto escalador que aprende a transformar datos solo con respecto a los datos de entrenamiento, ya que en teoría no se conocen los de test en el momento del aprendizaje.\n",
    "Se aplica luego la transformación a ambos conjuntos (train y test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z1jDqM6O2uzj"
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k3CxhxzA2uzk"
   },
   "source": [
    "## Modelamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LDtnUowN2uzk"
   },
   "source": [
    "Con una regresión logística nos habría ido así:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "id": "FfwSuTas2uzl",
    "outputId": "a2b2b7ba-7022-4697-8f66-d7d5c382dabb"
   },
   "outputs": [],
   "source": [
    "np.random.seed(1234)\n",
    "logreg = LogisticRegression(random_state=1, solver='lbfgs')\n",
    "logreg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mYQ2KyFA2uzm",
    "outputId": "2fdc115a-fafc-4e53-b2c0-a6f834bd4342"
   },
   "outputs": [],
   "source": [
    "y_pred = logreg.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred), \", Kappa:\", cohen_kappa_score(y_test, y_pred), \"\\n\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ytOkK-m90FQc",
    "outputId": "f0a85a35-7d63-4b85-a13c-47e5d9cc86e0"
   },
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AScswEyX2uzm"
   },
   "source": [
    "Con una red neuronal multi-capas obtenemos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JyJ-xq042uzn"
   },
   "outputs": [],
   "source": [
    "mlp = MLPClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "Pa_HXD7I2uzn",
    "outputId": "ed33f8b2-97e0-4312-b914-68add6a190a3"
   },
   "outputs": [],
   "source": [
    "np.random.seed(1234)\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(10,15,20), random_state=1, max_iter=500)\n",
    "mlp.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WDzAFNXo2uzo"
   },
   "source": [
    "input, 1 hidden    : 30 * (10) + 10\n",
    "1 hidden, 2 hidden : 10 * (15) + 15\n",
    "2 hidden, 3 hidden : 15 * (20) + 20\n",
    "3 hidden , output  : 20 * (1)  + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "urJqcuHn2uzo",
    "outputId": "1b57eac2-b112-4ebf-bba6-144186a431c2"
   },
   "outputs": [],
   "source": [
    "y_pred = mlp.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred), \", Kappa:\", cohen_kappa_score(y_test, y_pred), \"\\n\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HnXnXFCo2uzp"
   },
   "source": [
    "<font color = \"red\">Encuentre la mejor red neuronal utilizando **GridSearchCV**, buscando la mejor combinación de los parámetros siguientes:</font>\n",
    "* <font color = \"red\">**activation**: función de activación, a escoger entre 'logistic', 'tanh', 'relu' (valor por defecto)</font>\n",
    "* <font color = \"red\">**max_iter**: máximo número de épocas de entrenamiento (por defecto, 200). Puede que no se necesiten todas las especificadas si se llega a convergencia).</font>\n",
    "* <font color = \"red\">**hidden_layer_sizes**: topología de la red, vector indicando el número de neuronas por capa. Por defecto solo se tiene un capa escondidad con 100 neuronas: (100).</font>\n",
    "* <font color = \"red\">**learning_rate_init**: tasa de aprendizaje inicial (por defecto es constante aunque se puede modificar esta tasa a medida que se va avanzando en el número de épocas). Por defecto, el valor es 0.001. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LtLPDvRv2uzq"
   },
   "outputs": [],
   "source": [
    "activation_vec = ['logistic', 'relu', 'tanh']\n",
    "max_iter_vec = [10, 20, 50, 75, 100, 200, 300, 400, 500, 1000, 2000]\n",
    "hidden_layer_sizes_vec = [(10,), (20,), (30,), (10, 10), (20, 20), (30, 30), (20, 10), (30, 20, 10)]\n",
    "learning_rate_init_vec = [0.001, 0.002, 0.003, 0.004, 0.005, 0.006, 0.007, 0.008, 0.009, 0.01, 0.02, 0.03, 0.04, 0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zfy2sCXg2uzq"
   },
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(30,30,30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mqigv6PS2uzr"
   },
   "source": [
    "### activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ihiTzNM82uzr"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time() # Devuelve el tiempo actual en segundos desde el 1o de enero de 1970 (punto de referencia)\n",
    "\n",
    "np.random.seed(1234)\n",
    "parametros = {'activation': activation_vec\n",
    "              }\n",
    "scoring = {'kappa':make_scorer(cohen_kappa_score), 'accuracy':'accuracy'}\n",
    "grid = GridSearchCV(mlp, param_grid=parametros, cv=5, scoring=scoring, refit='accuracy', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yLVz04hd2uzs",
    "outputId": "0ed25491-e62c-4eac-bede-0f9e02ab00a8"
   },
   "outputs": [],
   "source": [
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Los parámetros del mejor modelo fueron {0}, que permiten obtener un Accuracy de {1:.2f}% y un Kappa del {2:.2f}%\".format(\n",
    "    grid.best_params_, grid.best_score_*100, grid.cv_results_['mean_test_kappa'][grid.best_index_]*100))\n",
    "end = time.time() # Tiempo después de finalizar el entrenamiento del modelo\n",
    "print(\"Tiempo total: {0:.2f} minutos\".format((end-start)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hKNPJoow2uzs"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame([(activation, acc*100, kappa*100) for (activation, acc, kappa) in\n",
    "                   zip(activation_vec,\n",
    "                       grid.cv_results_['mean_test_accuracy'],\n",
    "                       grid.cv_results_['mean_test_kappa'],\n",
    "                      )\n",
    "                   ], columns = ('activation', 'Accuracy', 'Kappa'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "psU1GWUn2uzt",
    "outputId": "4ff3e722-4f29-4f5e-f954-fa295c34985a"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ROidKgQw2uzt",
    "outputId": "a9dd798b-26d7-4792-f45c-2b4da3eba370"
   },
   "outputs": [],
   "source": [
    "y_pred = grid.best_estimator_.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred), \", Kappa:\", cohen_kappa_score(y_test, y_pred), \"\\n\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "caY7nVtw2u0J",
    "outputId": "373fb84d-93a8-43cb-b0c9-d29968b32eaa"
   },
   "outputs": [],
   "source": [
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5a1TDD3b2u0J"
   },
   "source": [
    "### max_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SrGBRWgc2u0K"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time() # Devuelve el tiempo actual en segundos desde el 1o de enero de 1970 (punto de referencia)\n",
    "\n",
    "np.random.seed(1234)\n",
    "parametros = {'max_iter':max_iter_vec\n",
    "              }\n",
    "scoring = {'kappa':make_scorer(cohen_kappa_score), 'accuracy':'accuracy'}\n",
    "grid = GridSearchCV(mlp, param_grid=parametros, cv=5, scoring=scoring, refit='accuracy', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1C0R0vq12u0K",
    "outputId": "22186fcf-f6f5-4313-ed5b-048075d6515f"
   },
   "outputs": [],
   "source": [
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Los parámetros del mejor modelo fueron {0}, que permiten obtener un Accuracy de {1:.2f}% y un Kappa del {2:.2f}\".format(\n",
    "    grid.best_params_, grid.best_score_*100, grid.cv_results_['mean_test_kappa'][grid.best_index_]*100))\n",
    "end = time.time() # Tiempo después de finalizar el entrenamiento del modelo\n",
    "print(\"Tiempo total: {0:.2f} minutos\".format((end-start)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8rLgtkgn2u0L"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame([(max_iter, acc*100, kappa*100) for (max_iter, acc, kappa) in\n",
    "                   zip(max_iter_vec,\n",
    "                       grid.cv_results_['mean_test_accuracy'],\n",
    "                       grid.cv_results_['mean_test_kappa'],\n",
    "                      )\n",
    "                   ], columns = ('max_iter', 'Accuracy', 'Kappa'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z0av-sQP2u0M",
    "outputId": "473e1225-fe95-4e86-a8bc-13ca208399b6"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "ax = plt.gca() # get current axis\n",
    "plt.plot(df.max_iter, df.Accuracy)\n",
    "plt.xlabel('max_iter')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Evolución del Accuracy en función de max_iter')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BdKOKaui2u0M",
    "outputId": "c5458f2a-8e88-4f49-b682-224749796a83"
   },
   "outputs": [],
   "source": [
    "y_pred = grid.best_estimator_.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred), \", Kappa:\", cohen_kappa_score(y_test, y_pred), \"\\n\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mXI5R6ba2u0N"
   },
   "source": [
    "### hidden_layer_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "muVM7Uyh2u0N"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time() # Devuelve el tiempo actual en segundos desde el 1o de enero de 1970 (punto de referencia)\n",
    "\n",
    "np.random.seed(1234)\n",
    "parametros = {'hidden_layer_sizes':hidden_layer_sizes_vec\n",
    "              }\n",
    "scoring = {'kappa':make_scorer(cohen_kappa_score), 'accuracy':'accuracy'}\n",
    "grid = GridSearchCV(mlp, param_grid=parametros, cv=5, scoring=scoring, refit='accuracy', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zBZgVstO2u0O",
    "outputId": "88bfda20-7afb-40b4-d841-44fa0be35052"
   },
   "outputs": [],
   "source": [
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Los parámetros del mejor modelo fueron {0}, que permiten obtener un Accuracy de {1:.2f}% y un Kappa del {2:.2f}\".format(\n",
    "    grid.best_params_, grid.best_score_*100, grid.cv_results_['mean_test_kappa'][grid.best_index_]*100))\n",
    "end = time.time() # Tiempo después de finalizar el entrenamiento del modelo\n",
    "print(\"Tiempo total: {0:.2f} minutos\".format((end-start)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DBO3H1kz2u0O"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame([(hidden_layer_sizes, acc*100, kappa*100) for (hidden_layer_sizes, acc, kappa) in\n",
    "                   zip(hidden_layer_sizes_vec,\n",
    "                       grid.cv_results_['mean_test_accuracy'],\n",
    "                       grid.cv_results_['mean_test_kappa'],\n",
    "                      )\n",
    "                   ], columns = ('hidden_layer_sizes', 'Accuracy', 'Kappa'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6EitMCzD2u0P",
    "outputId": "c31544fa-96da-4354-a37c-20b09240cf21"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jDuuw8aM2u0Q",
    "outputId": "a5839412-008c-4da9-91b8-1b8401573f0a"
   },
   "outputs": [],
   "source": [
    "y_pred = grid.best_estimator_.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred), \", Kappa:\", cohen_kappa_score(y_test, y_pred), \"\\n\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2X6bLd1H2u0Q"
   },
   "source": [
    "### learning_rate_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TKOgpz9H2u0Q"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time() # Devuelve el tiempo actual en segundos desde el 1o de enero de 1970 (punto de referencia)\n",
    "\n",
    "np.random.seed(1234)\n",
    "parametros = {'learning_rate_init':learning_rate_init_vec\n",
    "              }\n",
    "scoring = {'kappa':make_scorer(cohen_kappa_score), 'accuracy':'accuracy'}\n",
    "grid = GridSearchCV(mlp, param_grid=parametros, cv=5, scoring=scoring, refit='accuracy', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RL7DKnw12u0R",
    "outputId": "3c24f9df-21fa-4596-9d6d-16aefa3a9ad9"
   },
   "outputs": [],
   "source": [
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Los parámetros del mejor modelo fueron {0}, que permiten obtener un Accuracy de {1:.2f}% y un Kappa del {2:.2f}\".format(\n",
    "    grid.best_params_, grid.best_score_*100, grid.cv_results_['mean_test_kappa'][grid.best_index_]*100))\n",
    "end = time.time() # Tiempo después de finalizar el entrenamiento del modelo\n",
    "print(\"Tiempo total: {0:.2f} minutos\".format((end-start)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NKr8h2gn2u0R"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame([(learning_rate_init, acc*100, kappa*100) for (learning_rate_init, acc, kappa) in\n",
    "                   zip(learning_rate_init_vec,\n",
    "                       grid.cv_results_['mean_test_accuracy'],\n",
    "                       grid.cv_results_['mean_test_kappa'],\n",
    "                      )\n",
    "                   ], columns = ('learning_rate_init', 'Accuracy', 'Kappa'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Exdx45AZ2u0S",
    "outputId": "9952f2d8-efb1-4587-d7f1-d3df2cdea181"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "ax = plt.gca() # get current axis\n",
    "plt.plot(df.learning_rate_init, df.Accuracy)\n",
    "plt.xlabel('learning_rate_init')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Evolución del Accuracy en función de learning_rate_init')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cO72VMGU2u0S",
    "outputId": "d3a2e942-d1f2-43dd-a728-3ccd765269b8"
   },
   "outputs": [],
   "source": [
    "y_pred = grid.best_estimator_.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred), \", Kappa:\", cohen_kappa_score(y_test, y_pred), \"\\n\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xctOL2fx2u0T"
   },
   "source": [
    "### mejor combinación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uq0x1mKO2u0T"
   },
   "outputs": [],
   "source": [
    "activation_vec = ['logistic', 'relu', 'tanh']\n",
    "max_iter_vec = [10, 20, 50, 75, 100, 200, 300, 400, 500, 1000, 2000]\n",
    "hidden_layer_sizes_vec = [(10,), (20,), (30,), (10, 10), (20, 20), (30, 30), (20, 10),\n",
    "                          (10, 10, 10), (20, 20, 20), (30, 30, 30), (30, 20, 10)]\n",
    "learning_rate_init_vec = [0.001, 0.002, 0.003, 0.004, 0.005, 0.006, 0.007, 0.008, 0.009, 0.01, 0.02]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P3T0wwb52u0U"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time() # Devuelve el tiempo actual en segundos desde el 1o de enero de 1970 (punto de referencia)\n",
    "\n",
    "np.random.seed(1234)\n",
    "parametros = {'activation': activation_vec,\n",
    "              'max_iter':max_iter_vec,\n",
    "              'hidden_layer_sizes': hidden_layer_sizes_vec,\n",
    "              'learning_rate_init': learning_rate_init_vec\n",
    "              }\n",
    "scoring = {'kappa':make_scorer(cohen_kappa_score), 'accuracy':'accuracy'}\n",
    "grid = GridSearchCV(mlp, param_grid=parametros, cv=5, scoring=scoring, refit='accuracy', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iQgBkoYU2u0U"
   },
   "source": [
    "#### <font color=\"red\"><b>DESDE AQUÍ: NO EJECUTAR DE NUEVO (+20 minutos)</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VE4VfrdD2u0X",
    "outputId": "9e507ca7-e271-4a7a-d983-2c1e2cc3e6f1"
   },
   "outputs": [],
   "source": [
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Los parámetros del mejor modelo fueron {0}, que permiten obtener un Accuracy de {1:.2f}% y un Kappa del {2:.2f}\".format(\n",
    "    grid.best_params_, grid.best_score_*100, grid.cv_results_['mean_test_kappa'][grid.best_index_]*100))\n",
    "end = time.time() # Tiempo después de finalizar el entrenamiento del modelo\n",
    "print(\"Tiempo total: {0:.2f} minutos\".format((end-start)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QPon1e9k2u0Y"
   },
   "source": [
    "#### <font color=\"red\"><b>HASTA ACÁ (+20 minutos)</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NTAAI3EK2u0Y"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame([(acc*100, kappa*100) for (acc, kappa) in\n",
    "                   zip(\n",
    "                       grid.cv_results_['mean_test_accuracy'],\n",
    "                       grid.cv_results_['mean_test_kappa'],\n",
    "                      )\n",
    "                   ], columns = ('Accuracy', 'Kappa'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lVMRf7y22u0Z",
    "outputId": "d1f2eb01-3b33-4eea-fae2-2f9b1b640fb5"
   },
   "outputs": [],
   "source": [
    "df.iloc[np.argsort(-df.Accuracy),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U9GvXREy2u0Z",
    "outputId": "d6d16873-0704-4eac-9e45-cfb2685255a3"
   },
   "outputs": [],
   "source": [
    "grid.cv_results_.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e9NdjinN2u0Z",
    "outputId": "e331cabf-3376-427f-a829-87e40879b707"
   },
   "outputs": [],
   "source": [
    "y_pred = grid.best_estimator_.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred), \", Kappa:\", cohen_kappa_score(y_test, y_pred), \"\\n\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CEgvE96t2u0a"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame([(act, hidden_layers, lr, max_iter, acc*100, kappa*100) for (act, hidden_layers, lr, max_iter, acc, kappa) in\n",
    "                   zip(\n",
    "                       grid.cv_results_['param_activation'],\n",
    "                       grid.cv_results_['param_hidden_layer_sizes'],\n",
    "                       grid.cv_results_['param_learning_rate_init'],\n",
    "                       grid.cv_results_['param_max_iter'],\n",
    "                       grid.cv_results_['mean_test_accuracy'],\n",
    "                       grid.cv_results_['mean_test_kappa'],\n",
    "                      )\n",
    "                   ], columns = ('Activation', 'HiddenLayers', 'LearningRate', 'MaxIter', 'Accuracy', 'Kappa'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aO3rBYPd2u0a",
    "outputId": "feeab03d-026c-467b-a564-b829e64074bf"
   },
   "outputs": [],
   "source": [
    "    df.iloc[np.argsort(-df.Accuracy),].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iiN8WZym2u0a"
   },
   "source": [
    "# Búsqueda de parámetros con optimización bayesiana"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dYfxSGR02u0b"
   },
   "source": [
    "La optimización de los hiper parámetros la podemos hacer de varias maneras:\n",
    "- Grid search: lo que hemos hecho hasta ahora\n",
    "- Random search: escoger combinaciones de valores al azar dentro de un rango determinado para cada hiperparámetro de manera independiente\n",
    "- Optimización bayesiana: modelo de búsqueda \"inteligente\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "REmx2QN82u0b"
   },
   "source": [
    "La **optimización bayesiana** se basa en la maximización de una métrica, dado una configuración de hiperparámetros óptima.\n",
    "El paquete que vamos a utilizar es muy sencillo, y requiere la creación de una función \"caja negra\" que:\n",
    "- recibe como argumentos los hiperparámetros del flujo de modelo a calibrar\n",
    "- retorna una métrica que se quiere maximizar (e.g. el ROC AUC, el accuracy, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "afwSaKBs2u0b",
    "outputId": "73b447ac-5dff-4ddc-eec3-be65e610b110"
   },
   "outputs": [],
   "source": [
    "!pip install bayesian-optimization\n",
    "#conda install -c conda-forge bayesian-optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xd36b-X72u0c"
   },
   "source": [
    "Vamos a crear una función de ploteo que nos permita visualizar los avances. Esta función va a recibir un diccionario de datos y va a iterar sobre él, mostrando los resultados. Esta función se podrá llamar cada iteración de la búsqueda de hiperparámetros en el proceso de optimización bayesiana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4mE7-IWh2u0c"
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "def live_plot(data_dict, figsize=(7,5), title='', win_size: int = 100):\n",
    "    \"\"\"\n",
    "    Función para mostrar en tiempo real el progreso de la optmización bayesiana.\n",
    "    \"\"\"\n",
    "    clear_output(wait=True)\n",
    "    plt.figure(figsize=figsize)\n",
    "    for label,data in data_dict.items():\n",
    "        if len(data) > win_size:\n",
    "            data = data[-win_size:]\n",
    "            iterations = np.arange(len(data))[-win_size:]\n",
    "        else:\n",
    "            iterations = np.arange(len(data))\n",
    "        plt.plot(iterations, data, label=label)\n",
    "    plt.title(title)\n",
    "    plt.grid(True)\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.legend(loc='center left') # the plot evolves to the right\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_f9jMgsy3GF1"
   },
   "source": [
    "## Función de \"caja negra\" a optimizar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xBoESQWj2u0c"
   },
   "source": [
    "Creamos una función de \"caja negra\", encargada de entrenar un flujo del modelo que incluya un pretratamiento de las variables independientes (e.g. estandarización, imputación, etc.) y un modelo de clasificación con los hiperparámetros a testear.\n",
    "\n",
    "Esta función se llamará varias veces con diferentes valores de los hiper parámetros del flujo de entrenamiento, buscando la maximización del valor que ella retorna. El proceso de esta búsqueda lo hará la librería, una vez definamos la función de caja negra y los rangos de los valores posibles de los hiper parámetros.\n",
    "\n",
    "En este caso en particular, todas las variables son numéricas y continuas, sin embargo, para ilustrar un proceso en el que combinamos variables numéricas con categóricas, incluiremos en los flujos de entrenamiento ejemplos de  pretratamientos que deberíamos considerar en ambos casos.\n",
    "\n",
    "La optimización bayesiana supone que todos los hiper parámetros son numéricos y contínuos, por lo que para algunos de ellos que no lo son, nos tocará ser un poco creativos. A continuación explicamos como trataremos algunos de ellos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_QPzyWK43vqD"
   },
   "source": [
    "### Arquitectura de la red\n",
    "\n",
    "En el caso de un flujo que incluya una red neuronal, los hiper parámetros que definen la arquitectura de la red neuronal deben tener un tratamiento muy particular. No solo tenemos que buscar el número de capas escondidas, sino el número de neuronas de ellas.\n",
    "\n",
    "Vamos a partir de una arquitectura típica en que las primeras capas escondidas tienen mas neuronas que las siguientes. Para simplificar definimos un único hiper parámetro `model_hidden_layer_size_exp` que define toda la arquitectura. Su valor, después de convertido a entero, definirá una potencia de 2 que indicará el número de neuronas de la primera capa escondida.\n",
    "\n",
    "Por ejemplo, si este número es 5, la primera capa escondida tendrá 2^5=32 neuronas, la siguiente capa tendrá 2^4=16 neuronas, y así sucesivamente. Establecemos un límite de 2^2=4 neuronas para la última capa escondida, teniendo en cuenta que la capa de salida en estas redes tradicionales tiene siempre una única neurona. Si el valor de este hiper parámetro es inferior a 2, se definirá una única capa de 4 neuronas.\n",
    "En código establecemos entonces la arquitectura de la siguiente manera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bsYen6ZX6HZR",
    "outputId": "e63824ed-1a00-464d-c169-942ff9bed9a1"
   },
   "outputs": [],
   "source": [
    "# Este será el hiper parámetro que se definirá a través de la librería, establecemos un valor de prueba\n",
    "model_hidden_layer_size_exp=2.2\n",
    "max_exponent = int(model_hidden_layer_size_exp)\n",
    "# Se crea una lista con los valores de las potencias de 2 de la mayor a la menor (reversada)\n",
    "hidden_layer_sizes = [2**(n) for n in reversed(range(2, max_exponent+1))]\n",
    "print(f\"max_exponent: {max_exponent}\")\n",
    "print(f\"arquitectura: {hidden_layer_sizes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NB7mO-o22u0d",
    "outputId": "d84f8c85-70fc-4ae2-d3e8-2d4ef9fe17ce"
   },
   "outputs": [],
   "source": [
    "_ = [print(n) for n in reversed(range(2, max_exponent+1))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j_KYL6xa_cPG"
   },
   "source": [
    "### Hiper parámetros del back propagation del modelo de red neuronal tradicional\n",
    "\n",
    "El proceso de entrenamiento por back-propagation de la red neuronal requiere la definición de los siguientes hiper parámetros:\n",
    "- `model_lr_init`: learning rate a utilizar que controla la velocidad de las actualizaciones de los parámetros de la red\n",
    "- `model_alpha`: controla el nivel de regularización Ridge (L2) de las neuronas\n",
    "- `model_batch_size`: controla el tamaño del batch en el proceso de mini-batch gradient descent, también se define en términos de potencias de 2. Por ejemplo, un valor de 10.1 se convertirá en entero (10), y luego se tomará 2^10=1024 como tamaño del batch,\n",
    "- `model_max_iter`: define el número de épocas de iteración que se aplicarán en el entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gYY7nL9V2u0e"
   },
   "source": [
    "### Imputación de datos faltantes\n",
    "\n",
    "No hay que olvidar que estamos buscando los mejores hiper parámetros del proceso, no solo del modelo. Las redes neuronales no aceptan valores faltantes, por lo que hay que definir la estrategia de imputación.\n",
    "Podemos pensar en dos maneras de imputar (pueden ser muchas mas): una que involucre el `SimpleImputer` remplazando el valor faltante por el promedio o mediana, otra que utilice el `KNNImputer` remplazando el valor faltante por el promedio o mediana de sus `K` vecinos mas cercanos.\n",
    "\n",
    "Definimos los siguientes hiper parámetros de imputación:\n",
    "- `imputer_strategy`: recibe un valor entre 0 y 1, si es inferior a 0.5 se utilizará el promedio, sino, se utilizará la mediana\n",
    "- `imputer_class`: recibe un valor entre 0 y 1, si es inferior a 0.5 se utilizará el `SimpleImputer`, y para valores superiores a 0.5, se utilizará el `KNNImputer`.\n",
    "- `knn_imputer_k`: en el caso de utilizar un `KNNImputer` se necesitará definir ademas otro hiper parámetro que establecerá el número de vecinos cercanos a considerar y que no tendra incidencia en el caso de `SimpleImputer`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vE1dMCcz97wN"
   },
   "source": [
    "### Método de normalización\n",
    "\n",
    "Similar al caso anterior en el hecho de que se refiere a un pretratamiento de datos, definimos un hiper parámetro `scaler_choice` que controlará la normalización de los datos de entrada al modelo. Si su valor es inferior a 0.5 se escala, si es superior, se normaliza entre 0 y 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wLkd0f9P-hGc"
   },
   "source": [
    "### Tratamiento de variables categóricas\n",
    "\n",
    "Las variables categóricas deberán ser codificadas; en este caso utilizaremos `OneHotEncoder` para tal efecto.\n",
    "No definimos un hiper parámetro para este efecto, aunque podríamos considerar otros métodos de codificación como por ejemplo, **embeddings** (lo veremos en las sesiones de tratamiento de texto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aC0_xmPoDPgX"
   },
   "source": [
    "## Función de caja negra (la llamaremos `train_and_evaluate`)\n",
    "\n",
    "Escribimos el código de la función de caja negra teniendo en cuenta lo mencionado antes.\n",
    "\n",
    "Como lo hemos mencionado, el dataset es sencillo y no incluye variables categóricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iyQl7DrolfWk"
   },
   "outputs": [],
   "source": [
    "var_numericas = cancer.feature_names\n",
    "var_categoricas = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T9zF9wg_o4Ev",
    "outputId": "9e9692bd-d17d-4045-ae6a-a34bd5b0300a"
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FyTVB7On2u0e"
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from pprint import pprint\n",
    "import collections\n",
    "\n",
    "# Se crea un diccionario donde todos los valores son listas, de tal manera\n",
    "# que sea fácil agregar nuevos valores de las métricas de seguimiento\n",
    "# cada vez que se realice una iteración de entrenamiento, para poder ser\n",
    "# graficadas con la función `live_plot`\n",
    "data_plot = collections.defaultdict(list)\n",
    "\n",
    "def add_model(data_pipeline, model) -> Pipeline:\n",
    "    whole_pipeline = Pipeline([\n",
    "        (\"data_pipeline\", data_pipeline),\n",
    "        (\"model\", model)\n",
    "    ])\n",
    "    return whole_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SEjtqn4MOrbk"
   },
   "source": [
    "La función `train_and_evaluate` que creamos a continuación contiene el proceso de pretratamiento de la data, de entrenamiento del flujo del modelo y de evaluación con la métrica a optimizar.\n",
    "\n",
    "La vamos a \"empacar\" con una función wrapper mas adelante.\n",
    "De esta manera podremos definir argumentos que no sean hiperparámetros del flujo, como lo son `verbose`, que indica si se quiere indagar mas sobre el desarrollo del proceso, y `show_live_plot`, que indica si se quiere imprimir un plot con los resultados parciales de cada iteración en tiempo real.\n",
    "\n",
    "Además la función retorna tanto el modelo como la métrica que se desea optimizar; el proceso de optimización bayesiana del paquete que estamos utilizando requiere que solo se retorne un valor, que es lo que hará la función wrapper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4e2esPmqmybr"
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate(\n",
    "    #------------------------------------------\n",
    "    # Hiperparámetros de tratamiento de datos\n",
    "    #------------------------------------------\n",
    "\n",
    "    # Escala de los datos: vamos a escoger entre un MinMax y una estandarización\n",
    "    scaler_choice, # si <0.5: se estandariza, si >0.5: se normaliza entre 0 y 1\n",
    "\n",
    "    # Imputación: vamos a escoger entre un SimpleScaler y un KNNImputer\n",
    "    imputer_strategy, # si <0.5: se usa el promedio, si >0.5: se usa la mediana\n",
    "    imputer_class,    # si <0.5: se usa SimpleImputer, si >0.5: se usa KNNImputer\n",
    "    knn_imputer_k,    # hiperparámetro del KNNImputer\n",
    "\n",
    "    #------------------------------------------\n",
    "    # Hiperparámetros del modelo y de su entrenamiento\n",
    "    #------------------------------------------\n",
    "\n",
    "    # Model\n",
    "    model_hidden_layer_size_exp, #controla el número de neuronas y de capas\n",
    "    model_lr_init, #learning rate\n",
    "    model_alpha,\n",
    "    model_batch_size,\n",
    "    model_max_iter,\n",
    "    verbose=0,\n",
    "    show_live_plot=True\n",
    ") -> float: #Retorna un valor float\n",
    "\n",
    "    #----------------------------------------------\n",
    "    #--- Definición de tareas de pretratamiento ---\n",
    "    #----------------------------------------------\n",
    "\n",
    "    scaler_cls = StandardScaler if scaler_choice > 0.5 else MinMaxScaler\n",
    "    imputer_strategy = \"mean\" if imputer_strategy > 0.5 else \"median\"\n",
    "    if imputer_class > 0.5:\n",
    "        imputer = KNNImputer(n_neighbors=int(knn_imputer_k))\n",
    "    else:\n",
    "        imputer = SimpleImputer(strategy=imputer_strategy)\n",
    "\n",
    "    # Para las variables numéricas definimos un pipeline que impute\n",
    "    # valores faltantes, y luego normalice\n",
    "    numeric_transformer = Pipeline(\n",
    "        steps=[(\"imputer\", imputer), (\"scaler\", scaler_cls())]\n",
    "    )\n",
    "\n",
    "    # Para las variables categóricas definimos un column transformer\n",
    "    # que traduzca las categorías a variables one hot encoded\n",
    "    categorical_transformer = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "\n",
    "    # Creamos un Column Transformer con las tareas de preprocesamiento\n",
    "    # específicas a los dos tipos de variables\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", numeric_transformer, var_numericas),\n",
    "            (\"cat\", categorical_transformer, var_categoricas),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # El pipeline se crea con un primer paso de pretratamiento. Mas adelante\n",
    "    # se le agregará el paso del modelo.\n",
    "    data_pipeline = Pipeline(steps=[\n",
    "        (\"data_processor\", preprocessor),\n",
    "    ])\n",
    "\n",
    "    #---------------------------------\n",
    "    #--- Configuración del modelo  ---\n",
    "    #---------------------------------\n",
    "\n",
    "    max_exponent = int(model_hidden_layer_size_exp)\n",
    "    if max_exponent<2:\n",
    "        max_exponent=2\n",
    "\n",
    "    model_kwargs = dict(\n",
    "        hidden_layer_sizes = [2**(n) for n in reversed(range(2, max_exponent+1))],\n",
    "        batch_size=2**int(model_batch_size),\n",
    "        learning_rate_init=model_lr_init,\n",
    "        alpha=model_alpha,\n",
    "        max_iter=int(model_max_iter),\n",
    "        early_stopping=True,\n",
    "        random_state=42,\n",
    "    )\n",
    "\n",
    "    if verbose:\n",
    "        print(\"MLP Classifier params: \")\n",
    "        pprint(model_kwargs)\n",
    "\n",
    "    model = MLPClassifier(**model_kwargs)\n",
    "\n",
    "    pipeline = add_model(data_pipeline, model)\n",
    "\n",
    "    #------------------------------------------------\n",
    "    #--- Protocolo de entrenamiento y evaluación  ---\n",
    "    #------------------------------------------------\n",
    "\n",
    "    # Seguiremos un K-fold con 3 splits aleatorios\n",
    "    kf = KFold(n_splits=3, random_state=42, shuffle=True)\n",
    "\n",
    "    # para cada fold guardamos las métricas del training y validation set\n",
    "    train_fold_metrics = []\n",
    "    val_fold_metrics = []\n",
    "\n",
    "    # K-Fold cross val\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(df_X_train)):\n",
    "        #print(f\"Fold number: {i+1}\")\n",
    "        kX_train, kX_val = df_X_train.iloc[train_index], df_X_train.iloc[test_index]\n",
    "        ky_train, ky_val = df_y_train.iloc[train_index], df_y_train.iloc[test_index]\n",
    "        #print(f\"Training with {kX_train.shape}\")\n",
    "        #print(f\"Validating with {kX_val.shape}\")\n",
    "        pipeline.fit(kX_train, ky_train.squeeze())\n",
    "\n",
    "        train_preds = (pipeline.predict_proba(kX_train)[:, 1]> 0.5)\n",
    "        train_metric = accuracy_score(ky_train.squeeze(), train_preds)\n",
    "        train_fold_metrics.append(train_metric)\n",
    "\n",
    "        val_preds = (pipeline.predict_proba(kX_val)[:, 1]> 0.5)\n",
    "        val_metric = accuracy_score(ky_val.squeeze(), val_preds)\n",
    "        val_fold_metrics.append(val_metric)\n",
    "\n",
    "    train_metric_mean = np.array(train_fold_metrics).mean()\n",
    "    val_metric_mean = np.array(val_fold_metrics).mean()\n",
    "\n",
    "    if show_live_plot:\n",
    "        data_plot['train_metric'].append(train_metric_mean)\n",
    "        data_plot['val_metric'].append(val_metric_mean)\n",
    "        live_plot(data_plot)\n",
    "\n",
    "    return pipeline, val_metric_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r0NA2cpjG7Gw"
   },
   "source": [
    "La función `target_func` va a \"empacar\" la función `train_and_evaluate`, conformándose a lo esperado por el paquete de optimización bayesiana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rX8wy1AUG6PI"
   },
   "outputs": [],
   "source": [
    "def target_func(**kwargs):\n",
    "    model, result = train_and_evaluate(**kwargs)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OToRBRxQ2u0e"
   },
   "source": [
    "Ahora que hemos creado la función de caja negra la podemos llamar directamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 465
    },
    "id": "4djlrG5V2u0f",
    "outputId": "0441320e-a842-4dbd-df15-ae375d95bcd4"
   },
   "outputs": [],
   "source": [
    "flujo_de_modelo, metric = train_and_evaluate(\n",
    "    scaler_choice=0.3, # si <0.5: se estandariza, si >0.5: se normaliza entre 0 y 1\n",
    "    imputer_strategy=0.3, # si <0.5: se usa el promedio, si >0.5: se usa la mediana\n",
    "    imputer_class=0.3,    # si <0.5: se usa SimpleImputer, si >0.5: se usa KNNImputer\n",
    "    knn_imputer_k=0,      # hiperparámetro del KNNImputer\n",
    "    model_hidden_layer_size_exp=3, #controla el número de neuronas y de capas\n",
    "    model_lr_init=0.01,\n",
    "    model_alpha=0.01,\n",
    "    model_batch_size=6,\n",
    "    model_max_iter=50,\n",
    "    verbose=1,\n",
    "    show_live_plot=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "coZI5KMcRYj6"
   },
   "source": [
    "Podemos ver que por cada llamado, se agrega un valor a las métricas de seguimiento que vamos a plotear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q4a5XfxhIiTY",
    "outputId": "093aab11-3cec-4d89-ebca-b40eef8246f9"
   },
   "outputs": [],
   "source": [
    "data_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Y3ECtQU2u0k"
   },
   "source": [
    "Se debe crear una instancia de **BayesianOptimization**, especificando la función a optimizar, los hiperparámetros y sus dominios de búsqueda de valores, de donde se tomarán las configuraciones a evaluar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "95lEaBPp2u0k"
   },
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-mQumkkd2u0l"
   },
   "source": [
    "Definimos los intervalos sobre los cuáles se va a realizar la búsqueda para cada hiper parámetro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NY0PUgwY2u0l"
   },
   "outputs": [],
   "source": [
    "pbounds = {'scaler_choice': (0, 1), 'imputer_strategy': (0, 1), 'imputer_class': (0, 1), 'knn_imputer_k': (1,16),\n",
    "           'model_hidden_layer_size_exp': (2, 5), 'model_lr_init': (0.005, 0.5), 'model_alpha': (0.001, 1),\n",
    "           'model_batch_size':(3, 7), 'model_max_iter':(50,50)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xt-DmK-r2u0l"
   },
   "source": [
    "Creamos el optimizador bayesiano, especificando la función caja negra a maximizar y la configuración de hiper parámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s9p058n7Rkoe"
   },
   "outputs": [],
   "source": [
    "data_plot = collections.defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h6oMt5sA2u0l"
   },
   "outputs": [],
   "source": [
    "optimizer = BayesianOptimization(\n",
    "    f=target_func,\n",
    "    pbounds=pbounds,\n",
    "    random_state=42,\n",
    "    verbose=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aVzI9AAJ2u0l"
   },
   "source": [
    "Si se quiere empezar por una configuración en particular, se pueden programar antes de lanzar la búsqueda automática:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O_KLXFui2u0m"
   },
   "outputs": [],
   "source": [
    "optimizer.probe(\n",
    "    params={'scaler_choice': 0.3, 'imputer_strategy': 0.3, 'imputer_class': 0.3, 'knn_imputer_k': 1,\n",
    "            'model_hidden_layer_size_exp': 3, 'model_lr_init': 0.01, 'model_alpha': 0.01, 'model_batch_size': 6, 'model_max_iter': 50}, lazy=True)\n",
    "optimizer.probe(\n",
    "    params={'scaler_choice': 0.3, 'imputer_strategy': 0.3, 'imputer_class': 0.3, 'knn_imputer_k': 1,\n",
    "            'model_hidden_layer_size_exp': 2, 'model_lr_init': 0.1, 'model_alpha': 0.01, 'model_batch_size': 6, 'model_max_iter': 50}, lazy=True)\n",
    "optimizer.probe(\n",
    "    params={'scaler_choice': 0.3, 'imputer_strategy': 0.3, 'imputer_class': 0.3, 'knn_imputer_k': 1,\n",
    "            'model_hidden_layer_size_exp': 4, 'model_lr_init': 0.05, 'model_alpha': 0.01, 'model_batch_size': 6, 'model_max_iter': 50}, lazy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t1RheSRa2u0m"
   },
   "source": [
    "Se puede utilizar directamente el objeto de **BayesianOptimization**, usando su método **maximize** que optimiza la función definida. Entre los parámetros de este método los más importante son:\n",
    "\n",
    "- init_points: el número de pasos de exploración aleatorios a ejecutar para incializar el proceso gausiano.\n",
    "- n_iter: el número de iteraciones del proceso gausiano de búsqueda de configuraciones de hiperparámetros. A mayor número de pasos, mejor la maximización, pero mas largo el proceso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 534
    },
    "id": "T0ooRmwY2u0m",
    "outputId": "a9676ce3-e579-41bc-aa1a-8a9532113f22"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "optimizer.maximize(\n",
    "    init_points=2,\n",
    "    n_iter=30,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qBxtVJAe2u0m"
   },
   "source": [
    "Se puede retomar la búsqueda si se desea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 534
    },
    "id": "Kh_N5kUj2u0n",
    "outputId": "8ce2de4d-91d4-4a4a-ed24-63ad36e89c89"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "optimizer.maximize(\n",
    "    n_iter=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WNci6AtpXI8b"
   },
   "source": [
    "Se obtienen luego los hiperparámetros óptimos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c2fhIxfu2u0n",
    "outputId": "a42c70df-03a4-4f7d-ebe9-b9684221d865"
   },
   "outputs": [],
   "source": [
    "optimizer.max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yRos03SsXXze"
   },
   "source": [
    "Obtenemos el mejor modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AkPDaw38XZyJ"
   },
   "outputs": [],
   "source": [
    "best_model, best_result = train_and_evaluate(**optimizer.max[\"params\"], show_live_plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ebbJEJdlXkOo",
    "outputId": "a4183368-c4be-4485-888a-582dd932f088"
   },
   "outputs": [],
   "source": [
    "best_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ObUx-jtnXlo0"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
